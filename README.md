# When Thinking LLMs Lie: Unveiling the Strategic Deception in Representations of Reasoning Models

ğŸ” This repository contains the code and resources for our paper *"When Thinking LLMs Lie: Unveiling the Strategic Deception in Representations of Reasoning Models"*.


## ğŸ”§ Status

Some core components of the code have been uploaded for early access. More will follow.




